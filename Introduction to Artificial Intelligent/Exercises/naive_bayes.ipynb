{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "MVKjbKMDoAuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Precision, Recall, F1-score Formula:**\n",
        "\n",
        "The F1-score is the harmonic mean of precision and recall:\n",
        "\n",
        "$$\n",
        "F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "$$\n",
        "Precision = \\frac{TP}{TP + FP}\n",
        "$$\n",
        "\n",
        "$$\n",
        "Recall = \\frac{TP}{TP + FN}\n",
        "$$\n",
        "\n",
        "\n",
        "\\( TP \\) = True Positives  \n",
        "\\( FP \\) = False Positives  \n",
        "\\( FN \\) = False Negatives  "
      ],
      "metadata": {
        "id": "fADBSDBnCZeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categorical Naive Bayes\n",
        "\n",
        "| Rec. ID | Age    | Income | Student | Credit_Rating | Buy_Computer |\n",
        "|---------|--------|--------|---------|---------------|--------------|\n",
        "| 1       | Young  | High   | No      | Fair          | No           |\n",
        "| 2       | Young  | High   | No      | Excellent     | No           |\n",
        "| 3       | Medium | High   | No      | Fair          | Yes          |\n",
        "| 4       | Old    | Medium | No      | Fair          | Yes          |\n",
        "| 5       | Old    | Low    | Yes     | Fair          | Yes          |\n",
        "| 6       | Old    | Low    | Yes     | Excellent     | No           |\n",
        "| 7       | Medium | Low    | Yes     | Excellent     | Yes          |\n",
        "| 8       | Young  | Medium | No      | Fair          | No           |\n",
        "| 9       | Young  | Low    | Yes     | Fair          | Yes          |\n",
        "| 10      | Old    | Medium | Yes     | Fair          | Yes          |\n",
        "| 11      | Young  | Medium | Yes     | Excellent     | Yes          |\n",
        "| 12      | Medium | Medium | No      | Excellent     | Yes          |\n",
        "| 13      | Medium | High   | Yes     | Fair          | Yes          |\n",
        "| 14      | Old    | Medium | No      | Excellent     | No           |\n",
        "\n",
        "Given the features\n",
        "- Age\n",
        "- Income\n",
        "- Student\n",
        "- Credit_Rating\n",
        "\n",
        "Predict\n",
        "- Buy_Computer"
      ],
      "metadata": {
        "id": "QohqZhEMrSpv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AooiSFAZ6vT9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "data = {\n",
        "    'Age': ['Young', 'Young', 'Medium', 'Old', 'Old', 'Old', 'Medium', 'Young', 'Young', 'Old', 'Young', 'Medium', 'Medium', 'Old'],\n",
        "    'Income': ['High', 'High', 'High', 'Medium', 'Low', 'Low', 'Low', 'Medium', 'Low', 'Medium', 'Medium', 'Medium', 'High', 'Medium'],\n",
        "    'Student': ['No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No'],\n",
        "    'Credit_Rating': ['Fair', 'Excellent', 'Fair', 'Fair', 'Fair', 'Excellent', 'Excellent', 'Fair', 'Fair', 'Fair', 'Excellent', 'Excellent', 'Fair', 'Excellent'],\n",
        "    'Buy_Computer': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "encoder = OrdinalEncoder(categories=[['Young', 'Medium', 'Old'], ['Low', 'Medium', 'High'], ['No', 'Yes'], ['Fair', 'Excellent']])\n",
        "X = encoder.fit_transform(df[['Age', 'Income', 'Student', 'Credit_Rating']])\n",
        "y = df['Buy_Computer'].map({'No': 0, 'Yes': 1})\n",
        "\n",
        "for features, target in zip(X, y):\n",
        "    print(f\"Features: {features}, Target: {target}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = CategoricalNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "y_test_pred = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f'Testing Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Predict for a new sample\n",
        "new_data = encoder.transform([['Young', 'Medium', 'Yes', 'Fair']])\n",
        "prediction = model.predict(new_data)\n",
        "print(f\"Prediction: {'Yes' if prediction[0] == 1 else 'No'}\")"
      ],
      "metadata": {
        "id": "1kEwVMUD64q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gaussian Naive Bayes"
      ],
      "metadata": {
        "id": "XO7X96xGrzcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features: sepal length, sepal width, petal length, petal width\n",
        "y = iris.target  # Target: 0 = setosa, 1 = versicolour, 2 = virginica\n",
        "\n",
        "for features, target in zip(X, y):\n",
        "    print(\"Features:\")\n",
        "    print(f\"-sepal length: {features[0]}\")\n",
        "    print(f\"-sepal width: {features[1]}\")\n",
        "    print(f\"-petal length: {features[2]}\")\n",
        "    print(f\"-petal width: {features[3]}\")\n",
        "    print(f\"Target: {target} - {iris.target_names[target]}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "lLlnG9RvqRJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "y_test_pred = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f'Testing Accuracy: {test_accuracy * 100:.2f}%')\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred, target_names=iris.target_names))\n",
        "\n",
        "# Predict for a new sample\n",
        "new_data = [[4.9, 3.5, 1.6, 0.2]]  # Example new data\n",
        "prediction = model.predict(new_data)\n",
        "print(f\"Prediction: {iris.target_names[prediction[0]]}\")"
      ],
      "metadata": {
        "id": "PjqxkA--syuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Naive Bayes"
      ],
      "metadata": {
        "id": "VTyCt_4DBKyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Laplace Smoothing Formula:**\n",
        "\n",
        "Laplace smoothing is used in Na√Øve Bayes classification to handle zero probabilities by adding a small value (typically 1) to word counts.\n",
        "\n",
        "$$\n",
        "P(w_i | C) = \\frac{count(w_i, C) + \\alpha}{\\sum count(w_j, C) + \\alpha \\times |V|}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- \\( P(w_i | C) \\) = Probability of word \\( w_i \\) given class \\( C \\)\n",
        "- \\( count(w_i, C) \\) = Number of times word \\( w_i \\) appears in class \\( C \\)\n",
        "- \\( \\alpha \\) = Smoothing parameter (commonly set to 1 for Laplace smoothing)\n",
        "- \\( |V| \\) = Vocabulary size (total unique words)\n",
        "- \\( \\sum count(w_j, C) \\) = Total count of words in class \\( C \\)\n",
        "\n",
        "Laplace smoothing ensures that every word has a nonzero probability, even if it doesn't appear in the training data. This prevents probability multiplication from resulting in zero, which could otherwise break classification."
      ],
      "metadata": {
        "id": "yF_I6wviENiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "texts = [\n",
        "    # Spam messages\n",
        "    \"Congratulations! You've won a $1000 Walmart gift card. Go to http://bit.ly/123456 to claim now.\",  # spam\n",
        "    \"URGENT! Your mobile number has won ¬£2000 cash! Call 09061701461 now.\",  # spam\n",
        "    \"Free entry in 2 a weekly competition to win FA Cup final tkts. Text FA to 87121 to receive entry question(std txt rate)\",  # spam\n",
        "    \"You have been selected to receive a free iPhone. Click here to claim: http://freeiphone.com\",  # spam\n",
        "    \"Win a guaranteed $1000 cash or a $2000 prize. To claim, call 09050000327.\",  # spam\n",
        "    \"Get Viagra now at a discount! No prescription needed. Visit http://meds4you.com\",  # spam\n",
        "    \"Exclusive offer! Buy 1 get 1 free on all items. Shop now at http://shopnow.com\",  # spam\n",
        "    \"You have a new voicemail. Call 1234567890 to listen.\",  # spam\n",
        "    \"Your account has been compromised. Reset your password at http://secure-login.com\",  # spam\n",
        "    \"Earn $5000 per week from home. Ask me how!\",  # spam\n",
        "\n",
        "    # Ham messages\n",
        "    \"Hey, are we still meeting for dinner tonight?\",  # ham\n",
        "    \"Don't forget to bring your umbrella. It's going to rain.\",  # ham\n",
        "    \"Can you pick up some milk on your way home?\",  # ham\n",
        "    \"Happy Birthday! Hope you have a great day!\",  # ham\n",
        "    \"I'll call you when I get off work.\",  # ham\n",
        "    \"Just finished my workout. Feeling great!\",  # ham\n",
        "    \"Let's catch up soon. It's been a while!\",  # ham\n",
        "    \"I'm running late. Be there in 10 minutes.\",  # ham\n",
        "    \"Thanks for your help earlier. I really appreciate it.\",  # ham\n",
        "    \"Good luck on your exam tomorrow!\",  # ham\n",
        "]\n",
        "labels = [\"spam\"] * 10 + [\"ham\"] * 10"
      ],
      "metadata": {
        "id": "SSEnNgo90CMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "print(X_train[0])\n",
        "print(y_train[0])"
      ],
      "metadata": {
        "id": "Elo4LX6IBdVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_pipeline(CountVectorizer(), MultinomialNB(alpha=1.0, fit_prior=True))\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "y_test_pred = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f'Testing Accuracy: {test_accuracy * 100:.2f}%')\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "eBwsJgW1Bi-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB(alpha=1.0, fit_prior=True))\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "y_test_pred = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "print(f'Testing Accuracy: {test_accuracy * 100:.2f}%')\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "pFcrb2GbB4GC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}